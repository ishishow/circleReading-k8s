# 第三回 「WorkloadsAPIカテゴリ」~Deploymentまで

## メモ
- Pod単位でIP Addressが割り当てられる
- メインのコンテナを同一のPodに同居させるのは推奨されていない
- Pod名はRFC1123のホスト名の制約に則っている
- ホストのネットワーク構成を利用したPodの起動もできるが基本的には利用しない
- 通常Podはクラスタ内DNSを使って名前解決をしている（dnsPolicyがClusterFirst(default)のとき）
- Deploymentの更新の一時停止
- ローリングアップデート
- セルフヒーリング（ReplicaSet）
- ReplicaSetはPodのレプリカを作成し、指定した数のPodを維持し続けるリソースである
- recreate



## Podのデザインパターン


## シングルノード・マルチコンテナ・パターン

シングルノードで動作するアプリケーションを対象という意味ではなく、最も基本的なパターンとして、３つのパターンを挙げます。 

### サイドカー・パターン

ところで、サイドカーってなんだろう？と思う人は、少年漫画のヒーロー[人造人間キカイダーのサイドマシーン](https://blog.goo.ne.jp/spaceharrier/e/489152c6aa4df3c7fad6b7736305ace9) を見ると分かり易いとか思います。 バイクの側面に車をつけた乗り物をサイドカーと言います。

Kubernetesのポッドには、複数のコンテナを動かすことができます。　ポッドの中で、主となるコンテナを補助する様なコンテナを持つポッドを構造を持ったポッドをサイドカーと呼んでいます。


次の図の様に、ウェブサーバーの主コンテナを補助して、ログ転送するコンテナ、外部からコンテンツを定期的にプルするコンテナなどがあります。

![スクリーンショット 2018-03-06 19.38.55.png](https://qiita-image-store.s3.amazonaws.com/0/42829/6cedfabc-7fe8-6406-bcab-53ae315367f4.png "スクリーンショット 2018-03-06 19.38.55.png")


サイドカーの利点を列挙すると以下になります。

* Main コンテナは CPUを優先的に割り当て低レイテンシで応答させ、Sidecar コンテナは Mainコンテナが暇な時間を割り当てる
* 2つの独立したチーム間で開発の責任を分けやすくなり、独立してテストできる
* コンテナの再利用ができる。 Log Saverコンテナは、別の用途のログを出力するコンテナと組み合わせて利用できる
* コンテナは障害の封じ込めの境界を提供、全体が停止するのを防止する
* コンテナはデプロイの単位であり、各機能をアップグレードし、必要に応じて個別にロールバックできる


> コメント
k8sのポッドは、一つのIPアドレスを持ち、複数のコンテナが同時に稼働します。 そして各コンテナは、例えば、CentOS7 や Ubuntu 16.04 など異なるOSイメージのコンテナが動作させて、コンテナで開いたリッスンポートは、localhost 127.0.0.1のアドレス上のポート番号で相互にアクセスできます。このため、もちろん、コンテナ同士でポート番号が重ならない様に注意が必要です。また、ポッドをホストするノード上に一時的なボリュームを確保して、ポッドに永続ボリュームをアタッチして、コンテナ間のデータの受け渡し利用できます。 
サイドカーコンテナは、OSバージョンや開発言語を隠蔽して、同一IPホスト内で動作する独立性の高い画期的なユニットと言えます。 この同一ポットで複数のコンテナを動作させることで、フレームワークとアプリのコアを分離して、パターンを構成していける点が、これまでに無い新しさと思います。

> 参考資料
 [Kubernetes サイドカーの作り方とファイル共有](https://qiita.com/MahoTakara/items/c6db540a5a121cc7c2c2)



### アンバサダー・パターン

アンバサダーすなわち大使、使節、代表という意味で、外部のサービスを代表するコンテナを同一ポッド内に持つパターンです。 次の例では、Memcached や Redis のシャーディング用のツールとして利用される twemproxyを利用するケースです。 アプリケーション・コンテナから見れば、ローカルホストのポートをアクセスしているだけですが、シャーディングされて複数のMemcached へ分散されてデータが格納されます。　これによりキャッシュへのアクセス集中がボトルネックとなる事を回避することができます。 シャーディングを目的としているので、キャッシュの可用性は他の方法と組み合わせる必要があります。

![スクリーンショット 2018-03-06 19.53.35.png](https://qiita-image-store.s3.amazonaws.com/0/42829/6ad5f003-e9b9-664f-335e-edcaffd18904.png "スクリーンショット 2018-03-06 19.53.35.png")


アンバサダー・パターンの利点

* アプリの開発者は、シングルのサーバーをアクセスするだけの考慮で開発ができる
* テストの時は、シングルサーバーと接続してテストするだけで済む
* Twemproxyのアンバサダーコンテナは他のアプリケーション・コンテナと組み合わせて再利用できる


> コメント
アプリケーションのコンテナと同一のポットに、アンバサダー・コンテナを置く事で、ポッドのレプリカセットで複数もつ事できるので、プロキシーとなるプロセスの可用性も一緒に改善する事ができます。


### アダプター・パターン

こちらは、外部からのアクセスに対して、汎用的共通なインタフェースを持たせることを実現します。


![スクリーンショット 2018-03-06 20.12.23.png](https://qiita-image-store.s3.amazonaws.com/0/42829/5b4b989d-c0e9-465e-9ea0-c227e34bc28c.png "スクリーンショット 2018-03-06 20.12.23.png")


アダプター・パターンのユースケースとしては、次の様な様々なアプリケーションを共通のインターフェースでモニタリングする場合に利用されています。

![スクリーンショット 2018-03-06 20.55.27.png](https://qiita-image-store.s3.amazonaws.com/0/42829/89a5cd17-0948-9ae3-a567-68279959b5ad.png "スクリーンショット 2018-03-06 20.55.27.png")


> コメント
Kubernetesのダッシュボード用の時系列データベースの Prometheus は、プル型でデータを収集しますが、このアダプターパターンは、Prometheusのアダプターを想定したパターンであろうと思います。






## 分散アルゴリズム用のマルチノードパターン

モジュール化されたコンテナは、マルチノード分散アプリケーションの構築を容易する例を３つ挙げます。


### リーダ選出パターン

分散処理のノード間で、リーダー選出が必要な際に参考となるパターンです。

![スクリーンショット 2018-03-06 21.01.19.png](https://qiita-image-store.s3.amazonaws.com/0/42829/d4a5e6f5-07b3-10b2-297a-e5c1cd7092ec.png "スクリーンショット 2018-03-06 21.01.19.png")


Java言語で書かれたリーダ選出のライブラリを利用したプロセスをコンテナ化しておき、他のプログラム言語で書かれたコンテナと組み合わせて再利用します。

![スクリーンショット 2018-03-06 21.02.05.png](https://qiita-image-store.s3.amazonaws.com/0/42829/9af5980c-e233-8ea4-3906-b6bf1e7616fe.png "スクリーンショット 2018-03-06 21.02.05.png")

>コメント
サイドカーとして、リーダー選挙コンテナをポッドに同居させるもので、例えば、Javaで書かれたZooKeeperを利用したリーダー選挙コンテナとNode.jsなどで書いた分散アプリケーションを一つのポッドにまとめて、複数のレプリカセットを持つデプロイメントを構築する事が実現できることになります。


### 作業キューパターン

並列に処理可能な大量の処理を短時間で実行するためのパターンで、大量のメールの送信、様々のケースを評価して最適解を求めるモンテカルロ・シミュレーション、エンコーディング処理などの応用があります。 

![スクリーンショット 2018-03-06 21.03.19.png](https://qiita-image-store.s3.amazonaws.com/0/42829/51e472d5-0c43-93f7-c117-659af91b2fc3.png "スクリーンショット 2018-03-06 21.03.19.png")

>コメント
実装として、外部からの要求をRabbitMQへ格納して、アプリケーション・ポッドが、要求やデータをキューから取り出して、処理を進めていくタイプの並列処理が簡単に作れます。RabbitMQへ処理キューへ入れる部分、キューか要求を取り出す部分は、汎用的な処理ですから、再利用可能なコンテナとして、アプリケーションのコンテナと組み合わせる事ができます。 要求をキューから取り出したコンテナは、ポッドの共有ボリュームを使って、アプリケーション・コンテナへ、JSONやCSV形式などのファイルで渡す事ができます。 


### スキャッター・ギャザー・パターン

最後の分散システムパターンは、散布/収集です。 そのようなシステムでは、外部クライアントは「ルート」または「親」ノードに初期要求を送信します。 このルートは、並列に計算を実行するために要求を多数のサーバーに送ります。 各シャードは部分データを返し、ルートはこのデータを元の要求に対する単一の応答に集約します。


![スクリーンショット 2018-03-06 21.03.46.png](https://qiita-image-store.s3.amazonaws.com/0/42829/f0b7d9e0-f4d0-d958-7711-8dce7006ad7d.png "スクリーンショット 2018-03-06 21.03.46.png")

> コメント
要求やデータを小さな複数の範囲に分割して、並列に処理した後、再び統合して、一つの要求に対する結果として応答するものです。 検索エンジン、MapReduceタイプの処理などに適用する事ができます。





## ローリングアップデート
ローリングアップデートとは？
ローリングアップデートとは、同じ機能を持った複数のコンピュータで構成している場合のシステムをアップデートする手法の一つです。システムの稼動状態を維持しながら、1台ずつ順番にアップデートを行っていきます。

例えば、4台のWebサーバをロードバランサーで負荷分散しているシステムを例にとってみます。性能を犠牲にすることができる場合には、1台のコンピュータをロードバランサから切り離し、アップデートした後でシステムに組込むという作業を繰り返すことになります。
もし、性能を犠牲にすることができない場合には、別のコンピュータに新しいWebサーバを構築し、まず一台を入れ替えます。次に、入れ替えたコンピュータをアップデートして、また入れ替えをします。

このように、1台ずつを順番に入れ替えることからローリングアップデートと呼ばれています。

ローリングアップデート：性能を犠牲にできる場合とできない場合

ローリングアップデートのメリットとデメリット
ローリングアップデートのメリットは、無停止でシステムのバージョンアップを実現できることです。ただ、手順は非常に煩雑ですし、システムの切り替えが4回も発生する可能性があります。さらに、アップデート作業を行っている間は、2つのバージョンが混在することになります。
そのため、トラブルシューティングを行いにくかったり、管理の手順が違ってしまうなどのデメリットがあります。

Kubernetesのローリングアップデート
Kubernetesでは、ローリングアップデートを支援する機能を持っています。
Kubernetesのローリングアップデート機能は、デプロイメント内のPod数の上限を一時的に引き揚げます。そして、古いPodから新しいPodに順次入れ替えを行っていきます。一度にアップデートを行うPodの数は、設定によって調整することができます。

## カナリアリリース
　カナリアリリースとは新バージョンのアプリケーションをリリースする際に、従来バージョンのアプリケーションを並行稼働させ、一部のユーザーだけを新バージョンにアクセスさせる展開（デプロイ）手法のこと。新バージョンにアクセスするユーザーを炭鉱で毒ガスを検知する「カナリア」に見立てて、この名称が付けられた。

　カナリーリリース（canary release）、カナリーデプロイメント（canary deployment）、カナリーテスト（canary test）などとも呼ばれる。

　新バージョンのアプリケーションと従来バージョンのアプリケーションへの振り分け方法はいくつかあるが、ロードバランサーの機能を用いるケースが多い。この場合は一般に、ユーザーごとの振り分けではなくリクエストごとの振り分けになる。

カナリアリリースの仕組み
[画像のクリックで拡大表示]
　最初は5％や10％といった少ない割合のリクエストだけを新バージョンのアプリケーションに振り分け、問題が起きないことを確認しながら段階的に割合を増やしていく。全リクエストを新バージョンのアプリケーションに振り分けるようになったら、従来バージョンのアプリケーションを削除する。

　カナリアリリースを実践している企業としては米ネットフリックス（Netflix）が知られている。ネットフリックスは米グーグル（Google）とカナリアリリースの管理ソフト「Kayenta」を共同開発し、オープンソースソフト（OSS）として提供している。

https://cloud.google.com/blog/ja/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons

https://qiita.com/ozota/items/4126d85073175f66cb41

https://www.publickey1.jp/blog/18/googlenetflixkayenta.html

https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/canary-release.html

https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/create-canary-deployment.html



## Deploymentのアップデート戦略
https://cloud.google.com/architecture/application-deployment-and-testing-strategies?hl=ja

## k8sと継続的ソフトウェアデリバリーの課題
https://cloud.google.com/solutions/addressing-continuous-delivery-challenges-in-a-kubernetes-world?hl=ja